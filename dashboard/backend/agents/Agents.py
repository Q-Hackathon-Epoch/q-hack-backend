from langchain_core.language_models import BaseChatModel
from langchain_core.output_parsers import StrOutputParser
from typing import List, Dict
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai.chat_models import AzureChatOpenAI

from dashboard.backend.agents import Prompts

from dashboard.backend.utils.convert_to_text import convert_to_text


# for openai also you can use this
example_schema = {
    "name": "llm_response",
    "schema": {
        "type": "object",
        "properties": {
            "answer": {
                "type": "string",
                "description": "The response generated by the language model."
            },
            "combination": {
                "type": "array",
                "description": "A list of the predicates from the best combination.",
                "items": {
                    "type": "string"
                }
            }
        },
        "required": [
            "answer",
            "combination"
        ],
        "additionalProperties": False
    },
    "strict": True
}

def get_chat_prompt_template(system, user):
    return ChatPromptTemplate.from_messages([("system", system), ("human", user)])


llm = AzureChatOpenAI('gpt-4o')

class Agents:
    def __init__(self, llm_model: BaseChatModel):
        self.llm = llm_model

    def get_lectures(self, current_date: str, course_code: str, modules_text: str) -> Dict[str, List[str]]:
        prompt_template = get_chat_prompt_template(Prompts.system_lecture, Prompts.user_lecture)
        chain = prompt_template | self.llm.with_structured_output(example_schema)
        #raw_text = convert_to_text(file_path)
        result = chain.invoke({'current_date': current_date,
                               'course_code': course_code,
                               'modules_text': modules_text})
        return result

    def get_grades(self, current_date: str, lectures_mapping: dict, grades_text: str) -> Dict[str, List[str]]:
        prompt_template = get_chat_prompt_template(Prompts.system_grades, Prompts.user_grades)
        chain = prompt_template | self.llm.with_structured_output(example_schema)
        raw_text = convert_to_text(file_path)
        result = chain.invoke({'current_date': current_date,
                               'course_code': course_code,
                               'raw_text': raw_text})
        return result

